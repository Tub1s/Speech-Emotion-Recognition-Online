{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ravdess = \"./datasets/RAVDESS/audio_speech_actors_01-24/\"\n",
    "Crema = \"./datasets/CREMA-D/AudioWAV/\"\n",
    "Tess = \"./datasets/TESS/TESS Toronto emotional speech set data/\"\n",
    "Savee = \"./datasets/SAVEE/ALL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "for dir in ravdess_directory_list:\n",
    "    actor = os.listdir(Ravdess + dir)\n",
    "    for file in actor:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        file_emotion.append(int(part[2]))\n",
    "        file_path.append(Ravdess + dir + '/' + file)\n",
    "        \n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.drop(Ravdess_df.index[Ravdess_df['Emotions'] == 'calm'], inplace = True)\n",
    "Ravdess_df.drop(Ravdess_df.index[Ravdess_df['Emotions'] == 'surprise'], inplace = True)\n",
    "print(np.unique(Ravdess_df['Emotions'].values))\n",
    "Ravdess_df.to_csv(\"ravdess_paths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_directory_list = os.listdir(Crema)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in crema_directory_list:\n",
    "    file_path.append(Crema + file)\n",
    "    part=file.split('_')\n",
    "    if part[2] == 'SAD':\n",
    "        file_emotion.append('sad')\n",
    "    elif part[2] == 'ANG':\n",
    "        file_emotion.append('angry')\n",
    "    elif part[2] == 'DIS':\n",
    "        file_emotion.append('disgust')\n",
    "    elif part[2] == 'FEA':\n",
    "        file_emotion.append('fear')\n",
    "    elif part[2] == 'HAP':\n",
    "        file_emotion.append('happy')\n",
    "    elif part[2] == 'NEU':\n",
    "        file_emotion.append('neutral')\n",
    "    else:\n",
    "        file_emotion.append('Unknown')\n",
    "        \n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Crema_df.head()\n",
    "Crema_df.to_csv(\"crema_paths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    directories = os.listdir(Tess + dir)\n",
    "    for i, file in enumerate(directories):\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('_')\n",
    "        if len(part) == 3:\n",
    "            part = part[2]\n",
    "        else:\n",
    "            part = part[1]\n",
    "            \n",
    "        if part=='ps':\n",
    "            file_emotion.append('surprise')\n",
    "        else:\n",
    "            file_emotion.append(part)\n",
    "\n",
    "        if file[-4::] == \".wav\":\n",
    "            file_path.append(Tess + dir + '/' + file)\n",
    "        \n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions']) # Sprawdzic ktore dropnac, prawdopodobnie surprise\n",
    "\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Tess_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "\n",
    "Tess_df['Emotions'] = Tess_df['Emotions'].replace(['Sad', 'Fear', 'surprised'], ['sad', 'fear', 'surprise'])\n",
    "Tess_df.drop(Tess_df.index[Tess_df['Emotions'] == 'surprise'], inplace = True)\n",
    "\n",
    "Tess_df.to_csv(\"tess_paths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savee_directory_list = os.listdir(Savee)\n",
    "\n",
    "file_emotion = []\n",
    "file_path = []\n",
    "\n",
    "for file in savee_directory_list:\n",
    "    file_path.append(Savee + file)\n",
    "    part = file.split('_')[1]\n",
    "    ele = part[:-6]\n",
    "    if ele=='a':\n",
    "        file_emotion.append('angry')\n",
    "    elif ele=='d':\n",
    "        file_emotion.append('disgust')\n",
    "    elif ele=='f':\n",
    "        file_emotion.append('fear')\n",
    "    elif ele=='h':\n",
    "        file_emotion.append('happy')\n",
    "    elif ele=='n':\n",
    "        file_emotion.append('neutral')\n",
    "    elif ele=='sa':\n",
    "        file_emotion.append('sad')\n",
    "    else:\n",
    "        file_emotion.append('surprise')\n",
    "        \n",
    "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
    "\n",
    "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
    "Savee_df = pd.concat([emotion_df, path_df], axis=1)\n",
    "Savee_df.head()\n",
    "Savee_df.drop(Savee_df.index[Savee_df['Emotions'] == 'surprise'], inplace = True)\n",
    "Savee_df.to_csv(\"savee_paths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\n",
    "data_path.to_csv(\"data_path.csv\",index=False)\n",
    "data_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Rozkład klas dla zbioru danych SAVEE', size=16)\n",
    "sns.countplot(data_path.Emotions, palette = \"rocket\")\n",
    "sns.set_style(\"dark\")\n",
    "plt.ylabel('Liczba próbek', size=12)\n",
    "plt.xlabel('Emocje', size=12)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.savefig('./plots/rozklad_probek_dla_zbioru_SAVEE_')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_emotions = {\n",
    "    \"happy\": \"radość\",\n",
    "    \"disgust\": \"obrzydzenie\",\n",
    "    \"fear\": \"strach\",\n",
    "    \"angry\": \"gniew\",\n",
    "    \"sad\": \"smutek\",\n",
    "    \"neutral\": \"neurtalne\"\n",
    "}\n",
    "\n",
    "\n",
    "def create_waveplot(data, sr, e):\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    e = map_emotions[e]\n",
    "    plt.title('Wykres falowy dla przykładowego pliku audio z całego zbioru danych - charakter nagrania \"{}\"'.format(e), size=16)\n",
    "    librosa.display.waveplot(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def create_spectrogram(data, sr, e):\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    e = map_emotions[e]\n",
    "    plt.title('Spectrogram dla przykładowego pliku audio z całego zbioru danych - charakter nagrania \"{}\"'.format(e), size=16)\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')   \n",
    "    #librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    noise_amp = 0.03*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.7):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.6):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "path = np.array(data_path.Path)[1]\n",
    "data, sample_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data):\n",
    "    # ZCR\n",
    "    result = np.array([])\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr))\n",
    "\n",
    "    # Chroma_stft\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) \n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) \n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) \n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, mel)) \n",
    "    \n",
    "    #Spectral contrast\n",
    "    spcont = np.mean(librosa.feature.spectral_contrast(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, spcont)) \n",
    "    \n",
    "    #Spectral contrast\n",
    "    spcent = np.mean(librosa.feature.spectral_centroid(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, spcent)) \n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_features(path):\n",
    "    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "    \n",
    "    res1 = extract_features(data)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    noise_data = noise(data)\n",
    "    res2 = extract_features(noise_data)\n",
    "    result = np.vstack((result, res2))\n",
    "    \n",
    "    new_data = stretch(data)\n",
    "    data_stretch_pitch = pitch(new_data, sample_rate)\n",
    "    res3 = extract_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for path, emotion in tqdm(zip(data_path.Path, data_path.Emotions)):\n",
    "    if not isinstance(path, str):\n",
    "        continue\n",
    "    feature = get_features(path)\n",
    "    for ele in feature:\n",
    "        X.append(ele)\n",
    "        Y.append(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(Y), data_path.Path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = pd.DataFrame(X)\n",
    "Features['labels'] = Y\n",
    "Features.to_csv('all_features.csv', index=False)\n",
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Features.iloc[: ,:-1].values\n",
    "Y = Features['labels'].values\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size = 0.5, random_state=0, shuffle=True)\n",
    "print(x_test.shape, y_test.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "x_val = scaler.transform(x_val)\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_val = np.expand_dims(x_val, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"./saved_datasets/all_x_train.npy\", x_train)\n",
    "# np.save(\"./saved_datasets/all_y_train.npy\", y_train)\n",
    "# np.save(\"./saved_datasets/all_x_test.npy\", x_test)\n",
    "# np.save(\"./saved_datasets/all_y_test.npy\", y_test)\n",
    "# np.save(\"./saved_datasets/all_x_val.npy\", x_val)\n",
    "# np.save(\"./saved_datasets/all_y_val.npy\", y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
