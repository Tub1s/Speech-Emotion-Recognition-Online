{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), 'Physical GPUs,', len(logical_gpus), 'Logical GPUs')\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = \"savee\"\n",
    "# x_train = np.load(f\"./saved_datasets/{dataset}_x_train.npy\")\n",
    "# y_train = np.load(f\"./saved_datasets/{dataset}_y_train.npy\")\n",
    "# x_test = np.load(f\"./saved_datasets/{dataset}_x_test.npy\")\n",
    "# y_test = np.load(f\"./saved_datasets/{dataset}_y_test.npy\")\n",
    "# x_val = np.load(f\"./saved_datasets/{dataset}_x_val.npy\")\n",
    "# y_val = np.load(f\"./saved_datasets/{dataset}_y_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do użycia w przypadku trenowania nowych modeli\n",
    "\n",
    "# model=Sequential()\n",
    "# model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "# model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "# model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(units=32, activation='relu')) # Wariant 1\n",
    "\n",
    "# model.add(Dense(units=128, activation='relu')) # Wariant 2\n",
    "# model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(units=y_train.shape[1], activation='softmax'))\n",
    "# model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do użycia w przypadku dotrenowywania modeli\n",
    "\n",
    "# model_name = \"savee-tess-ravdess\"\n",
    "# dataset = \"cremad\"\n",
    "\n",
    "# x_train = np.load(f\"./saved_datasets/{dataset}_x_train.npy\")\n",
    "# y_train = np.load(f\"./saved_datasets/{dataset}_y_train.npy\")\n",
    "# x_test = np.load(f\"./saved_datasets/{dataset}_x_test.npy\")\n",
    "# y_test = np.load(f\"./saved_datasets/{dataset}_y_test.npy\")\n",
    "# x_val = np.load(f\"./saved_datasets/{dataset}_x_val.npy\")\n",
    "# y_val = np.load(f\"./saved_datasets/{dataset}_y_val.npy\")\n",
    "\n",
    "# print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape)\n",
    "\n",
    "# model = tf.keras.models.load_model(f'./models/{model_name}_alt_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
    "history=model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_val, y_val), callbacks=[rlrp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dokładność modelu na zbiorze testowym: \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")\n",
    "\n",
    "epochs = [i for i in range(50)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(epochs , train_loss , label = 'Wartość funkcji straty w na zbiorze treningowym')\n",
    "ax[0].plot(epochs , test_loss , label = 'Wartość funkcji straty w na zbiorze walidacyjnym')\n",
    "ax[0].set_title('Wartość funkcji straty na zbiorach treningowym i testowym')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epoki\")\n",
    "\n",
    "ax[1].plot(epochs , train_acc , label = 'Dokładność na zbiorze treningowym')\n",
    "ax[1].plot(epochs , test_acc , label = 'Dokładność na zbiorze walidacyjnym')\n",
    "ax[1].set_title('Dokładność na zbiorach treningowym i testowym')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epoki\")\n",
    "# plt.savefig(f\"./plots/{model_name}-{dataset}-model_alt_{dataset}-train_history\")\n",
    "# plt.savefig(f\"./plots/{dataset}-model_alt-train_history\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = pd.read_csv(f\"./features/{dataset}_features.csv\")\n",
    "Y = Features['labels'].values\n",
    "del Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "pred_test = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "\n",
    "y_test = encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\n",
    "df['Predicted Labels'] = y_pred.flatten()\n",
    "df['Actual Labels'] = y_test.flatten()\n",
    "\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "acd76c58f82936ed4ef55e996bd5fe7972426a02eeb8a4780d300a82c91ea7f5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
